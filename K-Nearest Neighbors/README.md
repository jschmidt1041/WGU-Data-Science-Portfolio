# K-Nearest Neighbors (KNN) Project

This project demonstrates the implementation and application of the **K-Nearest Neighbors (KNN)** algorithm for both classification and regression tasks. The project explores the effects of different parameters on model performance and illustrates how KNN can be used effectively for supervised learning problems.

---

## 📋 Project Overview

- **Objective:**  
  To build, train, and evaluate KNN models using a real-world dataset, understanding the impact of parameters such as the number of neighbors (k) and distance metrics.

- **Key Tasks:**  
  - Data preprocessing and feature scaling  
  - Implementing KNN classification and regression  
  - Model tuning with different k values  
  - Evaluating accuracy, precision, recall, and other metrics  
  - Visualizing decision boundaries and prediction results  

---

## 🛠️ Technologies Used

- Python  
- pandas, numpy  
- scikit-learn (for KNN implementation and evaluation)  
- matplotlib, seaborn (for data visualization)  
- Jupyter Notebook  

---

## 🚀 How to Run

1. Clone the repository or download this project folder.  
2. Open the Jupyter Notebook:  
   ```bash
   jupyter notebook K-Nearest\ Neighbors\ (KNN).ipynb
3. Run the cells sequentially to explore data loading, model building, evaluation, and visualization.

📈 Skills Demonstrated
- Supervised machine learning
- K-Nearest Neighbors algorithm
- Model tuning and evaluation
- Data preprocessing and feature scaling
- Visualization of classification boundaries

📬 Contact
For questions or feedback:
- Email: jessica.elaine.schmidt23@gmail.com
- LinkedIn: https://www.linkedin.com/in/jessica-elaine-schmidt/

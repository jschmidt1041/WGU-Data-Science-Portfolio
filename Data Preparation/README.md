# Data Cleaning Project
ğŸ“Œ Project Overview

Objective: To perform data cleaning and preprocessing on a raw dataset, including handling missing values, correcting data types, detecting and correcting anomalies, and preparing the dataset for analysis or modeling.

Tools Used:
- Python
- Pandas
- NumPy
- Matplotlib / Seaborn (for basic EDA)

ğŸ§¹ Key Cleaning Tasks
- Inspection of data quality and structure
- Imputation or removal of missing values
- Type conversions for consistency
- Detection and treatment of outliers
- Column renaming and feature engineering where needed
- Exporting the cleaned dataset for downstream use

ğŸ“ File
- Data Cleaning Project.ipynb: Main notebook showcasing the full cleaning pipeline with comments and explanations.
  Link: https://github.com/jschmidt1041/WGU-Data-Science-Portfolio/blob/main/Data%20Preparation/Data%20Cleaning%20Project.ipynb

âœ… Skills Demonstrated
- Data wrangling and quality assessment
- Use of Pandas for data transformation
- Exploratory data analysis (EDA) for verification
- Pythonic best practices for readable, maintainable code

ğŸ“Š Dataset
- A publicly available dataset (or synthetic sample) is used to illustrate real-world issues like inconsistent formats, null entries, and noisy values.
- Dataset source and description can be found within the notebook.

ğŸš€ How to Run
1. Clone the repository:
   git clone https://github.com/jschmidt1041/WGU-Data-Science-Portfolio.git
   cd WGU-Data-Science-Portfolio/Data Preparation/

2. Open the notebook:
   jupyter notebook "Data Cleaning Project.ipynb"

3. Follow the steps in the notebook to review and execute the data cleaning process.
   
ğŸ“¬ Contact
For questions, feedback, or collaboration inquiries, feel free to reach out:

- Email: jessica.elaine.schmidt23@gmail.com
- LinkedIn: https://www.linkedin.com/in/jessica-elaine-schmidt/
